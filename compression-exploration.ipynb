{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Asymmetric Numerical Systems (ANS, specifically rANS)\n",
    "\n",
    "ANS is a family of entropy codes developed by Jarek Duda (2009-2014) that offers:\n",
    "- High compression efficiency (similar to arithmetic coding)\n",
    "- High speed (often faster, especially on modern CPUs)\n",
    "\n",
    "Core Concept:\n",
    "- Maps symbols to states (integers)\n",
    "- Encodes these states\n",
    "\n",
    "Variants:\n",
    "1. tANS (tabled ANS)\n",
    "   - Used for static probability distributions\n",
    "   - Relies on precomputed tables\n",
    "\n",
    "2. rANS (range ANS)\n",
    "   - Flexible for adaptive probabilities\n",
    "   - More suitable for dynamic Transformer outputs\n",
    "\n",
    "Encoding Process (rANS):\n",
    "- Distributes integers (states) across symbols based on probabilities\n",
    "- Selects new state based on old state and symbol probability\n",
    "- Encodes state into bits (typically LIFO order)\n",
    "\n",
    "Decoding Process (rANS):\n",
    "- Reads bits to reconstruct state\n",
    "- Uses probability distribution and current state\n",
    "- Determines which symbol was encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_proc = -1 # CPUs go brrrr\n",
    "ds = load_dataset('commavq/commavq.py', data_dir='./commavq', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200, 8, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds['i'] is the ith data shard\n",
    "# ds['i'][x] is the x video (1 minute long / 1200 frames) in data shard 'i'\n",
    "# ds['i'][x]['path'] is the path to the video file\n",
    "\n",
    "\n",
    "tokens = []\n",
    "examples = 1  # len(ds['0'])\n",
    "for i in range(examples):\n",
    "    t = np.load(ds['0'][i]['path'])\n",
    "    t = torch.from_numpy(t)\n",
    "    tokens.append(t)\n",
    "\n",
    "tokens = torch.cat(tokens, dim=0)\n",
    "tokens.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Static Probability Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens: 1019\n",
      "Total tokens in the dataset: 153600\n",
      "Probability model (token_id: probability):\n",
      "  0: 0.000742\n",
      "  1: 0.000540\n",
      "  2: 0.002103\n",
      "  3: 0.000378\n",
      "  4: 0.003542\n",
      "  5: 0.000312\n",
      "  6: 0.000560\n",
      "  7: 0.000156\n",
      "  8: 0.000384\n",
      "  9: 0.000553\n",
      "  ...\n",
      "  1014: 0.001803\n",
      "  1015: 0.000957\n",
      "  1016: 0.001126\n",
      "  1017: 0.001510\n",
      "  1018: 0.001133\n",
      "  1019: 0.000807\n",
      "  1020: 0.000176\n",
      "  1021: 0.001211\n",
      "  1022: 0.000794\n",
      "  1023: 0.000885\n"
     ]
    }
   ],
   "source": [
    "# Calculate global token frequencies\n",
    "unique_tokens, counts = torch.unique(tokens, return_counts=True)\n",
    "\n",
    "# Calculate probabilities\n",
    "total_tokens = tokens.numel()\n",
    "probabilities = counts.float() / total_tokens\n",
    "\n",
    "# Display the probability model\n",
    "probability_model = {token.item(): prob.item() for token, prob in zip(unique_tokens, probabilities)}\n",
    "\n",
    "print(f\"Total unique tokens: {len(unique_tokens)}\")\n",
    "print(f\"Total tokens in the dataset: {total_tokens}\")\n",
    "print(\"Probability model (token_id: probability):\")\n",
    "# For brevity, let's print the first 10 and last 10 if the model is large\n",
    "sorted_probability_model = dict(sorted(probability_model.items()))\n",
    "items = list(sorted_probability_model.items())\n",
    "if len(items) > 20:\n",
    "    for token_id, prob in items[:10]:\n",
    "        print(f\"  {token_id}: {prob:.6f}\")\n",
    "    print(\"  ...\")\n",
    "    for token_id, prob in items[-10:]:\n",
    "        print(f\"  {token_id}: {prob:.6f}\")\n",
    "else:\n",
    "    for token_id, prob in items:\n",
    "        print(f\"  {token_id}: {prob:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
